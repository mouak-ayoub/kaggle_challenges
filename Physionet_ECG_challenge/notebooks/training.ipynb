{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-25T00:37:40.831089Z",
     "start_time": "2025-12-25T00:37:21.748260Z"
    }
   },
   "source": [
    "import os, glob, random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "DATA_ROOT = \"../data/train\"   # <-- change\n",
    "H_T, W_T = 850, 1100                # half-res of (1700,2200)\n",
    "K = 13\n",
    "\n",
    "BATCH_SIZE = 4                      # try 4; if OOM, drop to 2 or 1\n",
    "NUM_WORKERS = 2\n",
    "LR = 3e-4\n",
    "EPOCHS = 3                          # debug run first\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Dev\\ML\\workspace\\kaggle_challenges\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T00:39:18.891203Z",
     "start_time": "2025-12-25T00:39:18.877949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ECGSegDataset(Dataset):\n",
    "    def __init__(self, folders, H=H_T, W=W_T):\n",
    "        self.folders = folders\n",
    "        self.H, self.W = H, W\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.folders)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        d = self.folders[idx]\n",
    "        png_path = sorted(glob.glob(os.path.join(d, \"*0001.png\")))[0]\n",
    "        npz_path = sorted(glob.glob(os.path.join(d, \"mask-*.npz\")))[0]\n",
    "\n",
    "        # image\n",
    "        img = np.array(Image.open(png_path).convert(\"L\"), dtype=np.float32) / 255.0  # (H0,W0)\n",
    "        img_r = cv2.resize(img, (self.W, self.H), interpolation=cv2.INTER_AREA)      # (H,W)\n",
    "        x = torch.from_numpy(img_r[None, ...]).float()                               # (1,H,W)\n",
    "\n",
    "        # masks\n",
    "        z = np.load(npz_path, allow_pickle=True)\n",
    "        masks = z[\"masks\"]  # expected (H0,W0,13) uint8\n",
    "\n",
    "        if masks.ndim != 3:\n",
    "            raise ValueError(f\"Unexpected masks.ndim={masks.ndim} in {npz_path}\")\n",
    "        if masks.shape[-1] != K:\n",
    "            raise ValueError(f\"Expected last dim {K}, got {masks.shape} in {npz_path}\")\n",
    "\n",
    "        masks_r = np.zeros((self.H, self.W, K), dtype=np.uint8)\n",
    "        for k in range(K):\n",
    "            masks_r[..., k] = cv2.resize(masks[..., k], (self.W, self.H), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        y = torch.from_numpy(np.transpose(masks_r, (2,0,1))).float()  # (13,H,W)\n",
    "        return x, y\n"
   ],
   "id": "700234ad9c76ea57",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T00:40:09.627110Z",
     "start_time": "2025-12-25T00:40:08.955580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "folders = sorted([p for p in glob.glob(os.path.join(DATA_ROOT, \"*\")) if os.path.isdir(p)])\n",
    "random.shuffle(folders)\n",
    "\n",
    "val_n = max(200, int(0.1 * len(folders)))\n",
    "val_f = folders[:val_n]\n",
    "tr_f  = folders[val_n:]\n",
    "\n",
    "train_loader = DataLoader(ECGSegDataset(tr_f), batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader   = DataLoader(ECGSegDataset(val_f), batch_size=1, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "len(tr_f), len(val_f)\n"
   ],
   "id": "8a9034d524478d5a",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      5\u001B[39m val_f = folders[:val_n]\n\u001B[32m      6\u001B[39m tr_f  = folders[val_n:]\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m train_loader = \u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mECGSegDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtr_f\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m                          \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[43m=\u001B[49m\u001B[43mNUM_WORKERS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpin_memory\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m     10\u001B[39m val_loader   = DataLoader(ECGSegDataset(val_f), batch_size=\u001B[32m1\u001B[39m, shuffle=\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m     11\u001B[39m                           num_workers=NUM_WORKERS, pin_memory=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m     13\u001B[39m \u001B[38;5;28mlen\u001B[39m(tr_f), \u001B[38;5;28mlen\u001B[39m(val_f)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Dev\\ML\\workspace\\kaggle_challenges\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001B[39m, in \u001B[36mDataLoader.__init__\u001B[39m\u001B[34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device, in_order)\u001B[39m\n\u001B[32m    386\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# map-style\u001B[39;00m\n\u001B[32m    387\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m shuffle:\n\u001B[32m--> \u001B[39m\u001B[32m388\u001B[39m         sampler = \u001B[43mRandomSampler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgenerator\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[32m    389\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    390\u001B[39m         sampler = SequentialSampler(dataset)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Dev\\ML\\workspace\\kaggle_challenges\\.venv\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:162\u001B[39m, in \u001B[36mRandomSampler.__init__\u001B[39m\u001B[34m(self, data_source, replacement, num_samples, generator)\u001B[39m\n\u001B[32m    157\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[32m    158\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mreplacement should be a boolean value, but got replacement=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.replacement\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    159\u001B[39m     )\n\u001B[32m    161\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m.num_samples, \u001B[38;5;28mint\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m.num_samples <= \u001B[32m0\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m162\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    163\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mnum_samples should be a positive integer value, but got num_samples=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.num_samples\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    164\u001B[39m     )\n",
      "\u001B[31mValueError\u001B[39m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=K,\n",
    "    activation=None,   # logits\n",
    ").to(DEVICE)\n"
   ],
   "id": "b4b18f1636b2d1e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def dice_loss(logits, y, eps=1e-6):\n",
    "    p = torch.sigmoid(logits)\n",
    "    num = 2*(p*y).sum((2,3))\n",
    "    den = (p+y).sum((2,3)) + eps\n",
    "    return (1 - num/den).mean()\n",
    "\n",
    "def loss_fn(logits, y):\n",
    "    return bce(logits, y) + dice_loss(logits, y)\n",
    "\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n"
   ],
   "id": "bd732f354c11f81f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def run_epoch(loader, train=True):\n",
    "    model.train(train)\n",
    "    tot, n = 0.0, 0\n",
    "    for x, y in loader:\n",
    "        x = x.to(DEVICE, non_blocking=True)\n",
    "        y = y.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
    "            logits = model(x)\n",
    "            loss = loss_fn(logits, y)\n",
    "\n",
    "        if train:\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "\n",
    "        tot += loss.item()\n",
    "        n += 1\n",
    "    return tot / max(n, 1)\n",
    "\n",
    "best_val = float(\"inf\")\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    tr = run_epoch(train_loader, True)\n",
    "    va = run_epoch(val_loader, False)\n",
    "    print(f\"epoch {ep}/{EPOCHS} | train {tr:.4f} | val {va:.4f}\")\n",
    "\n",
    "    if va < best_val:\n",
    "        best_val = va\n",
    "        torch.save({\"model\": model.state_dict(), \"val_loss\": va}, \"best_unet_resnet34_halfres.pt\")\n",
    "        print(\"  saved best checkpoint\")\n"
   ],
   "id": "9346cd1b9356d1a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def pred_overlay(sample_idx=0, thr=0.5):\n",
    "    model.eval()\n",
    "    d = val_f[sample_idx]\n",
    "    png_path = sorted(glob.glob(os.path.join(d, \"*0001.png\")))[0]\n",
    "    npz_path = sorted(glob.glob(os.path.join(d, \"mask-*.npz\")))[0]\n",
    "\n",
    "    img0 = np.array(Image.open(png_path).convert(\"L\"), dtype=np.uint8)\n",
    "    img = cv2.resize(img0.astype(np.float32)/255.0, (W_T, H_T), interpolation=cv2.INTER_AREA)\n",
    "    x = torch.from_numpy(img[None,None,...]).float().to(DEVICE)\n",
    "\n",
    "    z = np.load(npz_path, allow_pickle=True)\n",
    "    gt0 = z[\"masks\"]\n",
    "    gt = np.zeros((H_T, W_T, K), dtype=np.uint8)\n",
    "    for k in range(K):\n",
    "        gt[..., k] = cv2.resize(gt0[..., k], (W_T, H_T), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)[0].detach().cpu().numpy()  # (K,H,W)\n",
    "        prob = 1/(1+np.exp(-logits))\n",
    "\n",
    "    pred_union = (prob.max(axis=0) > thr).astype(np.uint8)\n",
    "    gt_union   = (gt.max(axis=2) > 0).astype(np.uint8)\n",
    "\n",
    "    base = (img*255).astype(np.uint8)\n",
    "    base_rgb = np.stack([base]*3, axis=-1)\n",
    "\n",
    "    # overlay pred in red\n",
    "    out = base_rgb.copy()\n",
    "    m = pred_union.astype(bool)\n",
    "    out[m] = (0.5*out[m] + 0.5*np.array([255,0,0])).astype(np.uint8)\n",
    "\n",
    "    plt.figure(figsize=(16,5))\n",
    "    plt.subplot(1,3,1); plt.title(\"Half-res image\"); plt.imshow(base, cmap=\"gray\"); plt.axis(\"off\")\n",
    "    plt.subplot(1,3,2); plt.title(\"GT union\"); plt.imshow(gt_union, cmap=\"gray\"); plt.axis(\"off\")\n",
    "    plt.subplot(1,3,3); plt.title(\"Pred union overlay\"); plt.imshow(out); plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "pred_overlay(0, thr=0.5)\n"
   ],
   "id": "bad6903647b90ac6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

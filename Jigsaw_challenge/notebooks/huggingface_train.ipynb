{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T16:40:07.784105Z",
     "start_time": "2025-09-20T16:40:01.906701Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install evaluate",
   "id": "7fe7160bcd7b7ba0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (0.4.5)\n",
      "Requirement already satisfied: datasets>=2.0.0 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from evaluate) (4.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from evaluate) (2.2.6)\n",
      "Requirement already satisfied: dill in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from evaluate) (0.4.0)\n",
      "Requirement already satisfied: pandas in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from evaluate) (2.3.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from evaluate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from evaluate) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from evaluate) (0.35.0)\n",
      "Requirement already satisfied: packaging in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.19.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from datasets>=2.0.0->evaluate) (21.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from requests>=2.19.0->evaluate) (2025.8.3)\n",
      "Requirement already satisfied: colorama in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\dev\\ml\\workspace\\kaggle_challenges\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())   # True if CUDA is available\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device_count()) # Number of GPUs available"
   ],
   "id": "cfb4bf1e8099a9d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T15:40:57.051487Z",
     "start_time": "2025-09-20T15:40:55.035802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "# Fixed random seed for split reproducibility\n",
    "split_seed = 42\n",
    "\n"
   ],
   "id": "99d97fa25283261b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Dev\\ML\\workspace\\kaggle_challenges\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1. Load your dataset",
   "id": "663291fa043259"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "train_path=\"../data/train.csv\"\n",
    "test_dataset = load_dataset(\"csv\", data_files=train_path)\n",
    "train_dataset = test_dataset.rename_column(\"rule_violation\", \"label\").rename_column(\"body\", \"text\")"
   ],
   "id": "993ef918edd795b6"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-20T15:40:58.170558Z",
     "start_time": "2025-09-20T15:40:57.056700Z"
    }
   },
   "source": [
    "\n",
    "train_path=\"../data/train.csv\"\n",
    "dataset = load_dataset(\"csv\", data_files=train_path)\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.2, seed=split_seed)\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T15:40:58.485550Z",
     "start_time": "2025-09-20T15:40:58.471182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = train_dataset.rename_column(\"rule_violation\", \"label\").rename_column(\"body\", \"text\")\n",
    "test_dataset = test_dataset.rename_column(\"rule_violation\", \"label\").rename_column(\"body\", \"text\")\n"
   ],
   "id": "9977c0c0d7a2a08b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T15:40:58.502979Z",
     "start_time": "2025-09-20T15:40:58.497403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(train_dataset)\n",
    "print(train_dataset[0])\n",
    "print(train_dataset.column_names)\n",
    "\n"
   ],
   "id": "566d3f6e3ad63a0e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['row_id', 'text', 'rule', 'subreddit', 'positive_example_1', 'positive_example_2', 'negative_example_1', 'negative_example_2', 'label'],\n",
      "    num_rows: 1623\n",
      "})\n",
      "{'row_id': 1925, 'text': \"unethical but... make a SS# but state name and address and all perfectly.  If the IRS asks, just say that's the number you got, let the IRS sort if out for you.\", 'rule': 'No legal advice: Do not offer or request legal advice.', 'subreddit': 'personalfinance', 'positive_example_1': 'Dear dumbass, they stole $1700 dollars from him. I would have that person arrested regardless of who they are and what the money was used for. They committed fraud and identify theft against their own child, the only way someone with this kind of mentality will learn is by getting charged with a crime. ', 'positive_example_2': \"If she's been representing herself as a guest, and she wouldn't be permitted as your subtenant, then the way forward is clear, since she's not a tenant. You can evict her immediately, or perhaps with a courtesy 3 day notice, and if she doesn't clear out you can go to court to have an eviction ordered.\", 'negative_example_1': 'Why not just ask for the gun and shoot yourself in the exact same spot where you were shot originally to make a duplicate/ replica bullet?', 'negative_example_2': 'It looks like it could be a sterile cotton swab. Your child may be in deeper than you think - I know a lot of drug pushers that keep these for their customers. Does your child\\'s friends ever call him \"doctor\" or \"John Doe MD\"?', 'label': 1}\n",
      "['row_id', 'text', 'rule', 'subreddit', 'positive_example_1', 'positive_example_2', 'negative_example_1', 'negative_example_2', 'label']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2. Load a Tokenizer\n",
   "id": "8df310d47bc2db2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T15:41:28.984953Z",
     "start_time": "2025-09-20T15:41:26.498456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "train_dataset_tokenized = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset_tokenized = test_dataset.map(tokenize_function, batched=True)\n"
   ],
   "id": "f300ad4441927e3d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1623/1623 [00:01<00:00, 1232.24 examples/s]\n",
      "Map: 100%|██████████| 406/406 [00:00<00:00, 1323.08 examples/s]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T15:41:29.010274Z",
     "start_time": "2025-09-20T15:41:29.004378Z"
    }
   },
   "cell_type": "code",
   "source": "print(train_dataset_tokenized[0])",
   "id": "ab6cb4203937dc15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'row_id': 1925, 'text': \"unethical but... make a SS# but state name and address and all perfectly.  If the IRS asks, just say that's the number you got, let the IRS sort if out for you.\", 'rule': 'No legal advice: Do not offer or request legal advice.', 'subreddit': 'personalfinance', 'positive_example_1': 'Dear dumbass, they stole $1700 dollars from him. I would have that person arrested regardless of who they are and what the money was used for. They committed fraud and identify theft against their own child, the only way someone with this kind of mentality will learn is by getting charged with a crime. ', 'positive_example_2': \"If she's been representing herself as a guest, and she wouldn't be permitted as your subtenant, then the way forward is clear, since she's not a tenant. You can evict her immediately, or perhaps with a courtesy 3 day notice, and if she doesn't clear out you can go to court to have an eviction ordered.\", 'negative_example_1': 'Why not just ask for the gun and shoot yourself in the exact same spot where you were shot originally to make a duplicate/ replica bullet?', 'negative_example_2': 'It looks like it could be a sterile cotton swab. Your child may be in deeper than you think - I know a lot of drug pushers that keep these for their customers. Does your child\\'s friends ever call him \"doctor\" or \"John Doe MD\"?', 'label': 1, 'input_ids': [101, 16655, 23048, 2389, 2021, 1012, 1012, 1012, 2191, 1037, 7020, 1001, 2021, 2110, 2171, 1998, 4769, 1998, 2035, 6669, 1012, 2065, 1996, 25760, 5176, 1010, 2074, 2360, 2008, 1005, 1055, 1996, 2193, 2017, 2288, 1010, 2292, 1996, 25760, 4066, 2065, 2041, 2005, 2017, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3. Load a Pre-trained Model",
   "id": "5b4ffa58d8a06561"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T15:41:29.608407Z",
     "start_time": "2025-09-20T15:41:29.042331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# Load BERT for classification (binary here, adjust num_labels as needed)\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=2\n",
    ")\n",
    "print(model)"
   ],
   "id": "2d7d3a4b95184995",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4. Training Preparation",
   "id": "9cae71a34ada280f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T15:42:23.456928Z",
     "start_time": "2025-09-20T15:42:20.975351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset_tokenized,\n",
    "    eval_dataset=test_dataset_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n"
   ],
   "id": "3bb8f0819bd1b55b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_13248\\3449990728.py:21: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 5. Train the Model",
   "id": "d3f87889445deb61"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T16:40:01.488362Z",
     "start_time": "2025-09-20T15:42:23.542802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "trainer.train()\n",
    "\n"
   ],
   "id": "d00488d637459f1a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='609' max='609' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [609/609 57:30, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.671500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.587500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.552600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.513000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.386400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.397800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.343600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.362900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.228200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.241800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.277300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.283700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Dev\\ML\\workspace\\kaggle_challenges\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "D:\\Dev\\ML\\workspace\\kaggle_challenges\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=609, training_loss=0.40186620110948684, metrics={'train_runtime': 3456.1214, 'train_samples_per_second': 1.409, 'train_steps_per_second': 0.176, 'total_flos': 320271932136960.0, 'train_loss': 0.40186620110948684, 'epoch': 3.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 6. Evaluate the Model",
   "id": "c07cfd57ef749205"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(trainer.evaluate())",
   "id": "e710b7bcbc80ebe2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 7. Make Predictions for test file",
   "id": "84ae9795425e420c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "491fdc366aaba92a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
